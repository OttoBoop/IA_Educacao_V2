"""
Code Executor Service - Dual-Mode Architecture

Supports two execution backends:
- LocalDockerExecutor: Uses llm-sandbox + Docker (development)
- E2BExecutor: Uses E2B cloud service (production)

Switch between modes via EXECUTOR_MODE environment variable.
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
import asyncio
import base64
import hashlib
import os
import re
import time
import logging

# Load .env file
from dotenv import load_dotenv
load_dotenv()

logger = logging.getLogger(__name__)


# ============================================================
# ENUMS AND DATACLASSES
# ============================================================

class ExecutionStatus(Enum):
    """Status of code execution"""
    SUCCESS = "success"
    ERROR = "error"
    TIMEOUT = "timeout"
    SECURITY_VIOLATION = "security_violation"
    DOCKER_UNAVAILABLE = "docker_unavailable"


@dataclass
class GeneratedFile:
    """Represents a file generated by code execution"""
    filename: str
    extension: str
    content_base64: str
    mime_type: str
    size_bytes: int

    def to_dict(self) -> Dict[str, Any]:
        return {
            "filename": self.filename,
            "extension": self.extension,
            "content_base64": self.content_base64,
            "mime_type": self.mime_type,
            "size_bytes": self.size_bytes
        }


@dataclass
class ExecutionResult:
    """Result from code execution"""
    status: ExecutionStatus
    stdout: str = ""
    stderr: str = ""
    exit_code: int = 0
    execution_time_ms: float = 0
    files_generated: List[GeneratedFile] = field(default_factory=list)
    plots_generated: List[str] = field(default_factory=list)  # Base64 PNGs
    error_message: Optional[str] = None
    executor_mode: str = "local"

    def to_dict(self) -> Dict[str, Any]:
        return {
            "status": self.status.value,
            "stdout": self.stdout,
            "stderr": self.stderr,
            "exit_code": self.exit_code,
            "execution_time_ms": self.execution_time_ms,
            "files_generated": [f.to_dict() for f in self.files_generated],
            "plots_generated": self.plots_generated,
            "error_message": self.error_message,
            "executor_mode": self.executor_mode
        }

    @property
    def is_success(self) -> bool:
        return self.status == ExecutionStatus.SUCCESS


# ============================================================
# CONFIGURATION
# ============================================================

class CodeExecutorConfig:
    """Configuration for code executor"""

    def __init__(self):
        self.timeout_seconds: int = int(os.getenv("EXECUTOR_TIMEOUT_SECONDS", "60"))
        self.max_memory_mb: int = int(os.getenv("EXECUTOR_MAX_MEMORY_MB", "512"))
        self.docker_image: str = os.getenv("EXECUTOR_DOCKER_IMAGE", "python:3.11-slim")
        self.workdir: str = "/sandbox"
        self.enable_network: bool = False

        # Allowed libraries for document generation
        self.allowed_libraries: List[str] = [
            "pandas",
            "numpy",
            "matplotlib",
            "openpyxl",
            "xlsxwriter",
            "python-docx",
            "reportlab",
            "fpdf2",
            "python-pptx",
            "pillow",
            "seaborn",
            "tabulate",
        ]


# ============================================================
# SECURITY VALIDATOR
# ============================================================

class SecurityValidator:
    """Validates code before execution to prevent dangerous operations"""

    DANGEROUS_PATTERNS = [
        (r"\bos\.system\s*\(", "System command execution (os.system)"),
        (r"\bimport\s+subprocess\b", "Subprocess module import"),
        (r"\bfrom\s+subprocess\s+import\b", "Subprocess module import"),
        (r"\b__import__\s*\(", "Dynamic import"),
        (r"\beval\s*\(", "Eval execution"),
        (r"\bexec\s*\(", "Exec execution"),
        (r"\bcompile\s*\(", "Code compilation"),
        (r"\bopen\s*\([^,]+,\s*['\"][wa]", "File write outside sandbox"),
        (r"\bopen\s*\(\s*['\"]\/(?!home\/user|sandbox)", "File read outside allowed paths"),
        (r"\bsocket\.", "Network socket access"),
        (r"\brequests\.", "HTTP requests library"),
        (r"\bimport\s+urllib\b", "URL access library import"),
        (r"\bfrom\s+urllib\s+import\b", "URL access library import"),
        (r"\bimport\s+httpx\b", "HTTP client library import"),
        (r"\bimport\s+aiohttp\b", "Async HTTP library import"),
        (r"\bos\.environ", "Environment variable access"),
        (r"\bos\.getenv", "Environment variable access"),
        (r"\bos\.remove\b", "File deletion"),
        (r"\bos\.unlink\b", "File deletion"),
        (r"\bshutil\.rmtree\b", "Directory deletion"),
        (r"\bos\.rmdir\b", "Directory deletion"),
        (r"\b__builtins__\b", "Builtins access"),
        (r"\bglobals\s*\(\s*\)", "Globals access"),
        (r"\blocals\s*\(\s*\)", "Locals access"),
    ]

    def validate(self, code: str) -> Tuple[bool, List[str]]:
        """
        Validates code for security issues.

        Returns:
            Tuple of (is_safe, list_of_violations)
        """
        violations = []

        for pattern, description in self.DANGEROUS_PATTERNS:
            if re.search(pattern, code, re.IGNORECASE):
                violations.append(description)

        is_safe = len(violations) == 0
        return is_safe, violations


# ============================================================
# ABSTRACT EXECUTOR INTERFACE
# ============================================================

class ExecutorInterface(ABC):
    """Abstract interface for code execution backends"""

    @abstractmethod
    async def execute(
        self,
        code: str,
        libraries: Optional[List[str]] = None,
        output_files: Optional[List[str]] = None,
        context_files: Optional[Dict[str, bytes]] = None
    ) -> ExecutionResult:
        """
        Execute Python code in a sandboxed environment.

        Args:
            code: Python code to execute
            libraries: Additional pip packages to install
            output_files: Expected output filenames to retrieve
            context_files: Files to copy into sandbox before execution

        Returns:
            ExecutionResult with outputs and generated files
        """
        pass

    @abstractmethod
    async def check_availability(self) -> Tuple[bool, str]:
        """
        Check if the executor backend is available.

        Returns:
            Tuple of (is_available, status_message)
        """
        pass


# ============================================================
# LOCAL DOCKER EXECUTOR
# ============================================================

class LocalDockerExecutor(ExecutorInterface):
    """Docker-based execution via llm-sandbox (development)"""

    def __init__(self, config: CodeExecutorConfig = None):
        self.config = config or CodeExecutorConfig()
        self.security = SecurityValidator()
        self._output_dir = Path("./data/code_outputs")
        self._output_dir.mkdir(parents=True, exist_ok=True)

    async def check_availability(self) -> Tuple[bool, str]:
        """Check if Docker is available and running"""
        try:
            import docker
            client = docker.from_env()
            client.ping()
            return True, "Docker is available and running"
        except ImportError:
            return False, "Docker Python package not installed. Run: pip install docker"
        except Exception as e:
            return False, f"Docker not available: {str(e)}"

    async def execute(
        self,
        code: str,
        libraries: Optional[List[str]] = None,
        output_files: Optional[List[str]] = None,
        context_files: Optional[Dict[str, bytes]] = None
    ) -> ExecutionResult:
        """Execute code in Docker sandbox using llm-sandbox"""

        start_time = time.time()

        # Security validation
        is_safe, violations = self.security.validate(code)
        if not is_safe:
            return ExecutionResult(
                status=ExecutionStatus.SECURITY_VIOLATION,
                error_message=f"Security violations detected: {', '.join(violations)}",
                executor_mode="local"
            )

        # Check Docker availability
        docker_available, docker_msg = await self.check_availability()
        if not docker_available:
            return ExecutionResult(
                status=ExecutionStatus.DOCKER_UNAVAILABLE,
                error_message=docker_msg,
                executor_mode="local"
            )

        # Filter libraries to allowed list
        libs = libraries or []
        libs = [l for l in libs if l in self.config.allowed_libraries]

        try:
            # Import llm-sandbox
            from llm_sandbox import SandboxSession

            # Generate unique execution ID
            execution_id = hashlib.md5(f"{time.time()}{code[:100]}".encode()).hexdigest()[:8]

            # Run in thread pool since llm-sandbox is synchronous
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                self._execute_sync,
                code, libs, output_files, context_files, execution_id
            )

            result.execution_time_ms = (time.time() - start_time) * 1000
            return result

        except ImportError:
            return ExecutionResult(
                status=ExecutionStatus.ERROR,
                error_message="llm-sandbox not installed. Run: pip install 'llm-sandbox[docker]'",
                execution_time_ms=(time.time() - start_time) * 1000,
                executor_mode="local"
            )
        except asyncio.TimeoutError:
            return ExecutionResult(
                status=ExecutionStatus.TIMEOUT,
                error_message=f"Execution exceeded {self.config.timeout_seconds}s timeout",
                execution_time_ms=(time.time() - start_time) * 1000,
                executor_mode="local"
            )
        except Exception as e:
            logger.exception("Error executing code in Docker sandbox")
            return ExecutionResult(
                status=ExecutionStatus.ERROR,
                error_message=str(e),
                execution_time_ms=(time.time() - start_time) * 1000,
                executor_mode="local"
            )

    def _execute_sync(
        self,
        code: str,
        libraries: List[str],
        output_files: Optional[List[str]],
        context_files: Optional[Dict[str, bytes]],
        execution_id: str
    ) -> ExecutionResult:
        """Synchronous execution wrapper for llm-sandbox"""

        from llm_sandbox import SandboxSession

        with SandboxSession(
            lang="python",
            keep_template=True,
            verbose=False
        ) as session:

            # Copy context files into sandbox
            if context_files:
                for filename, content in context_files.items():
                    temp_path = self._output_dir / f"temp_{execution_id}_{filename}"
                    temp_path.write_bytes(content)
                    try:
                        session.copy_to_runtime(str(temp_path), f"{self.config.workdir}/{filename}")
                    finally:
                        temp_path.unlink(missing_ok=True)

            # Execute code
            result = session.run(code, libraries=libraries if libraries else None)

            # Retrieve generated files
            generated_files = []
            if output_files:
                for filename in output_files:
                    try:
                        local_path = self._output_dir / f"output_{execution_id}_{filename}"
                        session.copy_from_runtime(f"{self.config.workdir}/{filename}", str(local_path))

                        if local_path.exists():
                            content = local_path.read_bytes()
                            generated_files.append(GeneratedFile(
                                filename=filename,
                                extension=Path(filename).suffix,
                                content_base64=base64.b64encode(content).decode(),
                                mime_type=self._get_mime_type(filename),
                                size_bytes=len(content)
                            ))
                            local_path.unlink()
                    except Exception as e:
                        logger.warning(f"Failed to retrieve {filename}: {e}")

            # Also check for FILE_GENERATED: markers in stdout
            for line in result.stdout.split('\n'):
                if line.startswith('FILE_GENERATED:'):
                    remote_path = line.replace('FILE_GENERATED:', '').strip()
                    filename = Path(remote_path).name

                    if filename not in [f.filename for f in generated_files]:
                        try:
                            local_path = self._output_dir / f"output_{execution_id}_{filename}"
                            session.copy_from_runtime(remote_path, str(local_path))

                            if local_path.exists():
                                content = local_path.read_bytes()
                                generated_files.append(GeneratedFile(
                                    filename=filename,
                                    extension=Path(filename).suffix,
                                    content_base64=base64.b64encode(content).decode(),
                                    mime_type=self._get_mime_type(filename),
                                    size_bytes=len(content)
                                ))
                                local_path.unlink()
                        except Exception as e:
                            logger.warning(f"Failed to retrieve {filename} from FILE_GENERATED marker: {e}")

            return ExecutionResult(
                status=ExecutionStatus.SUCCESS if result.exit_code == 0 else ExecutionStatus.ERROR,
                stdout=result.stdout,
                stderr=result.stderr,
                exit_code=result.exit_code,
                files_generated=generated_files,
                executor_mode="local"
            )

    def _get_mime_type(self, filename: str) -> str:
        """Get MIME type for a file based on extension"""
        ext = Path(filename).suffix.lower()
        mime_map = {
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.xls': 'application/vnd.ms-excel',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.pdf': 'application/pdf',
            '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            '.ppt': 'application/vnd.ms-powerpoint',
            '.csv': 'text/csv',
            '.json': 'application/json',
            '.txt': 'text/plain',
            '.html': 'text/html',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml',
        }
        return mime_map.get(ext, 'application/octet-stream')


# ============================================================
# E2B CLOUD EXECUTOR
# ============================================================

class E2BExecutor(ExecutorInterface):
    """E2B cloud execution (production)"""

    def __init__(self, config: CodeExecutorConfig = None):
        self.config = config or CodeExecutorConfig()
        self.security = SecurityValidator()
        self.api_key = os.getenv("E2B_API_KEY")

    async def check_availability(self) -> Tuple[bool, str]:
        """Check if E2B is configured and available"""
        if not self.api_key:
            return False, "E2B_API_KEY not set. Get your key from https://e2b.dev/dashboard"

        try:
            from e2b_code_interpreter import Sandbox
            return True, "E2B is configured and available"
        except ImportError:
            return False, "e2b-code-interpreter not installed. Run: pip install e2b-code-interpreter"

    async def execute(
        self,
        code: str,
        libraries: Optional[List[str]] = None,
        output_files: Optional[List[str]] = None,
        context_files: Optional[Dict[str, bytes]] = None
    ) -> ExecutionResult:
        """Execute code in E2B cloud sandbox"""

        start_time = time.time()

        # Security validation (extra layer on top of E2B's sandboxing)
        is_safe, violations = self.security.validate(code)
        if not is_safe:
            return ExecutionResult(
                status=ExecutionStatus.SECURITY_VIOLATION,
                error_message=f"Security violations detected: {', '.join(violations)}",
                executor_mode="e2b"
            )

        # Check availability
        available, msg = await self.check_availability()
        if not available:
            return ExecutionResult(
                status=ExecutionStatus.ERROR,
                error_message=msg,
                executor_mode="e2b"
            )

        try:
            from e2b_code_interpreter import Sandbox

            # Filter libraries to allowed list
            libs = libraries or []
            libs = [l for l in libs if l in self.config.allowed_libraries]

            # Run in thread pool since e2b operations may be blocking
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                self._execute_sync,
                code, libs, output_files, context_files
            )

            result.execution_time_ms = (time.time() - start_time) * 1000
            return result

        except Exception as e:
            logger.exception("Error executing code in E2B sandbox")
            return ExecutionResult(
                status=ExecutionStatus.ERROR,
                error_message=str(e),
                execution_time_ms=(time.time() - start_time) * 1000,
                executor_mode="e2b"
            )

    def _execute_sync(
        self,
        code: str,
        libraries: List[str],
        output_files: Optional[List[str]],
        context_files: Optional[Dict[str, bytes]]
    ) -> ExecutionResult:
        """Synchronous execution wrapper for E2B"""

        from e2b_code_interpreter import Sandbox

        with Sandbox.create() as sandbox:
            # Install required libraries using Jupyter magic command syntax
            if libraries:
                pip_install = f"!pip install -q {' '.join(libraries)}"
                sandbox.run_code(pip_install)

            # Upload context files
            if context_files:
                for filename, content in context_files.items():
                    sandbox.files.write(f"/home/user/{filename}", content)

            # Execute the code
            execution = sandbox.run_code(code)

            # Collect output
            stdout = ""
            stderr = ""

            for log in execution.logs.stdout:
                stdout += log + "\n"
            for log in execution.logs.stderr:
                stderr += log + "\n"

            # Check for errors
            if execution.error:
                return ExecutionResult(
                    status=ExecutionStatus.ERROR,
                    stdout=stdout.strip(),
                    stderr=stderr.strip(),
                    error_message=str(execution.error),
                    executor_mode="e2b"
                )

            # Retrieve generated files
            generated_files = []
            if output_files:
                for filename in output_files:
                    try:
                        # Use format="bytes" for binary files (xlsx, pdf, docx, pptx, etc.)
                        # This ensures binary data is not corrupted by text encoding
                        content = sandbox.files.read(f"/home/user/{filename}", format="bytes")

                        # Convert bytearray to bytes if needed
                        if isinstance(content, bytearray):
                            content = bytes(content)

                        generated_files.append(GeneratedFile(
                            filename=filename,
                            extension=Path(filename).suffix,
                            content_base64=base64.b64encode(content).decode(),
                            mime_type=self._get_mime_type(filename),
                            size_bytes=len(content)
                        ))
                    except Exception as e:
                        logger.warning(f"Failed to retrieve {filename} from E2B: {e}")

            # Collect any plots/results
            plots_generated = []
            if execution.results:
                for result in execution.results:
                    if hasattr(result, 'png') and result.png:
                        plots_generated.append(result.png)

            return ExecutionResult(
                status=ExecutionStatus.SUCCESS,
                stdout=stdout.strip(),
                stderr=stderr.strip(),
                exit_code=0,
                files_generated=generated_files,
                plots_generated=plots_generated,
                executor_mode="e2b"
            )

    def _get_mime_type(self, filename: str) -> str:
        """Get MIME type for a file based on extension"""
        ext = Path(filename).suffix.lower()
        mime_map = {
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.xls': 'application/vnd.ms-excel',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.pdf': 'application/pdf',
            '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            '.csv': 'text/csv',
            '.json': 'application/json',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
        }
        return mime_map.get(ext, 'application/octet-stream')


# ============================================================
# FACTORY FUNCTION
# ============================================================

def get_executor() -> ExecutorInterface:
    """
    Factory function that returns the appropriate executor based on environment.

    Set EXECUTOR_MODE=e2b for production (E2B cloud) - DEFAULT
    Set EXECUTOR_MODE=local for development (Docker)
    """
    mode = os.getenv("EXECUTOR_MODE", "e2b").lower()
    config = CodeExecutorConfig()

    if mode == "e2b":
        logger.info("Using E2B cloud executor")
        return E2BExecutor(config)
    else:
        logger.info("Using local Docker executor")
        return LocalDockerExecutor(config)


# ============================================================
# HELPER FUNCTIONS
# ============================================================

def detect_libraries_from_code(code: str) -> List[str]:
    """
    Detect required libraries from Python code imports.

    Returns list of pip package names.
    """
    import_map = {
        "openpyxl": "openpyxl",
        "pandas": "pandas",
        "numpy": "numpy",
        "docx": "python-docx",
        "pptx": "python-pptx",
        "reportlab": "reportlab",
        "fpdf": "fpdf2",
        "matplotlib": "matplotlib",
        "PIL": "pillow",
        "seaborn": "seaborn",
        "tabulate": "tabulate",
        "xlsxwriter": "xlsxwriter",
    }

    libraries = []

    for import_name, pip_name in import_map.items():
        # Match both "import X" and "from X import"
        pattern = rf"\b(?:import\s+{import_name}|from\s+{import_name}\b)"
        if re.search(pattern, code):
            libraries.append(pip_name)

    return list(set(libraries))


def detect_output_files_from_code(code: str) -> List[str]:
    """
    Detect output files from Python code.

    Looks for patterns like:
    - .save('filename.xlsx')
    - .to_excel('filename.xlsx')
    - .savefig('filename.png')
    - print('FILE_GENERATED:/path/filename.xlsx')
    """
    output_files = []

    # Common save patterns
    patterns = [
        r"\.save\s*\(\s*['\"]([^'\"]+)['\"]",
        r"\.to_excel\s*\(\s*['\"]([^'\"]+)['\"]",
        r"\.to_csv\s*\(\s*['\"]([^'\"]+)['\"]",
        r"\.savefig\s*\(\s*['\"]([^'\"]+)['\"]",
        r"FILE_GENERATED:\s*([^\s'\"]+)",
        r"wb\.save\s*\(\s*['\"]([^'\"]+)['\"]",
        r"document\.save\s*\(\s*['\"]([^'\"]+)['\"]",
    ]

    for pattern in patterns:
        matches = re.findall(pattern, code)
        for match in matches:
            filename = Path(match).name  # Get just the filename
            if filename not in output_files:
                output_files.append(filename)

    return output_files


# ============================================================
# GLOBAL INSTANCE
# ============================================================

# Create global executor instance
code_executor = get_executor()
